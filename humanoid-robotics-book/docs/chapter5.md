---
sidebar_position: 5
---

# Chapter 5: Vision-Language-Action (VLA)

**Focus**: The convergence of LLMs and Robotics.

- **Voice-to-Action**: Using OpenAI Whisper for voice commands to direct the robot.
- **Cognitive Planning**: Employing LLMs to translate natural language commands (e.g., "Clean the room") into a sequence of executable ROS 2 actions.
- **Capstone Project**: The Autonomous Humanoid. A final project where a simulated robot receives a voice command, plans a path, navigates obstacles, identifies an object using computer vision, and manipulates it.
